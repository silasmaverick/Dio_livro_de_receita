{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/silas/data/juros_selic/juros_selic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "juros = spark.read.csv(\"/user/silas/data/juros_selic/juros_selic\", sep=\";\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alterar o formato do campo data para “MM/dd/yyyy”\n",
    "juros.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     data|valor|\n",
      "+---------+-----+\n",
      "|517968000| 1,27|\n",
      "|520560000| 1,95|\n",
      "|523238400| 2,57|\n",
      "|525916800| 2,94|\n",
      "|528508800| 1,96|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- data: long (nullable = true)\n",
      " |-- valor: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "juros_americano = juros.withColumn(\"data\", unix_timestamp(col(\"data\"), \"dd/MM/yyyy\"))\n",
    "juros_americano.show(5)\n",
    "juros_americano.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "juros_americano_new = juros_americano.withColumn(\"data\", from_unixtime(\"data\", \"MM/dd/yyyy\"))\n",
    "#juros_americano_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Com uso da função from_unixtime crie o campo “ano_unix”, com a informação do ano do campo data\n",
    "juros_unixtime = juros_americano_new.withColumn(\"ano_unix\",from_unixtime(unix_timestamp(col(\"data\"),\"dd/MM/yyy\"),\"yyyy\"))\n",
    "#juros_unixtime.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Com uso de substring crie o campo “ano_str”, com a informação do ano do campo data\n",
    "juros_substring = juros_unixtime.withColumn(\"ano_str\", substring(col(\"data\"),7,4))\n",
    "#juros_substring.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Com uso da função split crie o campo “ano_str”, com a informação do ano do campo data\n",
    "juros_split = juros_substring.withColumn(\"ano_split\", split(col(\"data\"),\"/\").getItem(2))\n",
    "#juros_split.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "juros_split.write.csv(\"/user/silas/juros_selic\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar um dataframe para ler o arquivo no HDFS /user/<nome/data/juros_selic/juros_selic\n",
    "juros_selic = spark.read.csv(\"/user/silas/data/juros_selic/juros_selic\", header=\"true\", sep=\";\")\n",
    "#juros_selic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: string (nullable = true)\n",
      " |-- valor: float (nullable = true)\n",
      " |-- ano: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Agrupar todas as datas pelo ano em ordem decrescente e salvar a quantidade de meses ocorridos, o valor médio, \n",
    "#mínimo e máximo do campo valor com a seguinte estrutura:\n",
    "juros_ano = juros_selic.withColumn(\"ano\", split(col(\"data\"), \"/\").getItem(2))\n",
    "juros_valor = juros_ano.withColumn(\"valor\", regexp_replace(col(\"valor\"),\"\\,\",\"\\.\").cast(FloatType()))\n",
    "juros_valor.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+------------+-------------+\n",
      "| ano|Meses|Valor médio|Valor minimo|Valor máximo)|\n",
      "+----+-----+-----------+------------+-------------+\n",
      "|1986|    7|       2.65|        1.27|         5.47|\n",
      "|1987|   12|      13.52|        7.99|        24.63|\n",
      "|1988|   12|      22.73|       16.59|        30.24|\n",
      "|1989|   12|      31.68|       11.43|        64.21|\n",
      "|1990|   12|      25.40|        4.23|        82.04|\n",
      "+----+-----+-----------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "juros_relatorio = juros_valor.groupBy(\"ano\").agg(count(\"ano\").alias(\"Meses\"),\n",
    "                                                 format_number(avg(\"valor\"),2).alias(\"Valor médio\"),\n",
    "                                                 min(\"valor\").alias(\"Valor minimo\"),\n",
    "                                                 max(\"valor\").alias(\"Valor máximo)\")).sort(asc(\"ano\"))\n",
    "juros_relatorio.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvar no hdfs:///user/<nome>/relatorioAnual com compressão zlib e formato orc\n",
    "#juros_relatorio.write.orc(\"user/silas/relatorio_anual\", compression=\"zlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls hdfs://namenode:8020/user/root/user/silas/relatorio_anual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
